{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5337ddfe",
   "metadata": {},
   "source": [
    "# Generaci√≥n de Contenido de Marketing con IA para ESU Analytics  \n",
    "\n",
    "Este cuaderno de Jupyter presenta una **prueba de concepto (POC)** orientada a la generaci√≥n de contenido de marketing digital para **ESU Analytics**, una consultora especializada en acompa√±ar a PyMEs de los sectores manufacturero y comercial en la profesionalizaci√≥n de su estrategia de datos.  \n",
    "\n",
    "La POC tiene como prop√≥sito:  \n",
    "- **Demostrar** c√≥mo aplicar t√©cnicas de *Fast Prompting* para optimizar la creaci√≥n de publicaciones en LinkedIn.  \n",
    "- **Experimentar** con diferentes configuraciones de prompts para evaluar su impacto en la claridad, relevancia y consistencia del contenido generado.  \n",
    "- **Controlar costos y eficiencia**, implementando l√≠mites de tokens y buenas pr√°cticas de uso del modelo `gpt-4o-mini` de OpenAI.  \n",
    "- **Garantizar trazabilidad**, exportando cada ejecuci√≥n con su *input* (brief y prompt generado) y *output* (texto final y m√©tricas de tokens).  \n",
    "\n",
    "De esta manera, se busca comprobar si las t√©cnicas aprendidas permiten mejorar la propuesta de soluci√≥n planteada en la etapa anterior, asegurando un flujo de generaci√≥n de contenido **m√°s √°gil, profesional y reproducible**, que apoye la estrategia de visibilidad digital de ESU Analytics.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9413a188",
   "metadata": {},
   "source": [
    "## Par√°metros del brief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9549cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par√°metros del brief que gu√≠an el prompt\n",
    "\n",
    "# Ejemplo comentado de valores posibles:\n",
    "# brief_tema = \"C√≥mo ordenar datos de ventas para tomar decisiones mejor informadas\",\n",
    "brief_tema = \"C√≥mo ordenar datos de ventas para tomar decisiones mejor informadas\",\n",
    "# brief_objetivo = \"Educar y generar inter√©s por un diagn√≥stico inicial\",\n",
    "brief_objetivo = \"Educar y generar inter√©s por un diagn√≥stico inicial\",\n",
    "# brief_audiencia = \"Due√±os de PyMEs retail y gerentes comerciales\",\n",
    "brief_audiencia = \"Due√±os de PyMEs retail y gerentes comerciales\",\n",
    "# brief_insight = \"Sin datos limpios y consistentes, el margen se vuelve impredecible\",\n",
    "brief_insight = \"Sin datos limpios y consistentes, el margen se vuelve impredecible\",\n",
    "# brief_evidencia = \"Planillas dispersas generan errores; unificarlas reduce reprocesos\",\n",
    "brief_evidencia = \"Planillas dispersas generan errores; unificarlas reduce reprocesos\",\n",
    "# brief_cta = \"Agend√° una consulta gratuita para revisar tu caso\",\n",
    "brief_cta = \"Agend√° una consulta gratuita para revisar tu caso\",\n",
    "# brief_restricciones = \"m√°x. 110 palabras, sin hashtags ni emojis\"\n",
    "brief_restricciones = \"m√°x. 110 palabras, sin hashtags ni emojis\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100c6a78",
   "metadata": {},
   "source": [
    "## üì¶ 0. Setup (variables y helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cbec8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as y configurar cliente\n",
    "import os, time, json\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca7246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la API Key desde .env\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Tokenizer para modelos GPT-4o/mini\n",
    "ENCODING_NAME = \"o200k_base\"\n",
    "enc = tiktoken.get_encoding(ENCODING_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "676bc18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones auxiliares\n",
    "def truncate_by_tokens(text: str, max_tokens: int) -> str:\n",
    "    tokens = enc.encode(text)\n",
    "    if len(tokens) <= max_tokens:\n",
    "        return text\n",
    "    return enc.decode(tokens[:max_tokens])\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(enc.encode(text))\n",
    "\n",
    "def now_ms():\n",
    "    return round(time.time() * 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c24d6a",
   "metadata": {},
   "source": [
    "## üß™ 1. Prompt builder (variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d33a570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"Eres un creador de contenido para ESU Analytics, consultora que ayuda a PyMEs de Manufactura y Comercio a profesionalizar su estrategia de datos (ventas, stock, estrategia comercial).\n",
    "Tu prioridad: claridad, utilidad pr√°ctica para due√±os/gerentes PyME en Argentina, tono profesional y cercano, y una llamada a la acci√≥n concreta.\n",
    "Responde siempre en espa√±ol de Buenos Aires neutral.\n",
    "\"\"\"\n",
    "\n",
    "USER_TEMPLATE = \"\"\"Tarea: Escribe un post de LinkedIn.\n",
    "\n",
    "Brief:\n",
    "- Tema: {tema}\n",
    "- Objetivo del post: {objetivo}\n",
    "- Audiencia: {audiencia}\n",
    "- √Ångulo/Insight: {insight}\n",
    "- Evidencia/ejemplo breve (opcional): {evidencia}\n",
    "- CTA: {cta}\n",
    "- Restricciones: {restricciones}\n",
    "\n",
    "Formato deseado:\n",
    "- 3‚Äì5 l√≠neas, con una idea central y un cierre con CTA.\n",
    "- Incluye 1 micro-lista de 3 √≠tems si aporta claridad.\n",
    "- No uses hashtags en esta versi√≥n.\n",
    "\n",
    "Entrega:\n",
    "Devuelve SOLO un objeto JSON con:\n",
    "{{\n",
    " \"titulo\": \"...\",\n",
    " \"cuerpo\": \"...\",\n",
    " \"cta\": \"...\",\n",
    " \"palabras\": <int>\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "def build_user_prompt(tema, objetivo, audiencia, insight, evidencia, cta, restricciones):\n",
    "    return USER_TEMPLATE.format(\n",
    "        tema=tema,\n",
    "        objetivo=objetivo,\n",
    "        audiencia=audiencia,\n",
    "        insight=insight,\n",
    "        evidencia=evidencia or \"‚Äî\",\n",
    "        cta=cta,\n",
    "        restricciones=restricciones\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b069525f",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 2. Llamada a OpenAI con l√≠mites de costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9204878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_post(brief, \n",
    "                  max_input_tokens=800, \n",
    "                  max_output_tokens=220, \n",
    "                  temperature=0.3):\n",
    "    user_prompt = build_user_prompt(**brief)\n",
    "    user_prompt = truncate_by_tokens(user_prompt, max_input_tokens)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\",   \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    t0 = now_ms()\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=max_output_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    dt = now_ms() - t0\n",
    "\n",
    "    text = resp.choices[0].message.content\n",
    "\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "    except Exception:\n",
    "        data = {\"raw\": text}\n",
    "\n",
    "    meta = {\n",
    "        \"elapsed_ms\": dt,\n",
    "        \"input_tokens_est\": count_tokens(SYSTEM_PROMPT) + count_tokens(user_prompt),\n",
    "        \"output_tokens_est\": count_tokens(text),\n",
    "        \"total_tokens_est\": count_tokens(SYSTEM_PROMPT) + count_tokens(user_prompt) + count_tokens(text),\n",
    "        \"api\": \"chat.completions\",\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"max_output_tokens\": max_output_tokens,\n",
    "        \"temperature\": temperature\n",
    "    }\n",
    "    # üëá devolvemos tambi√©n el prompt de usuario final para trazabilidad\n",
    "    return data, meta, user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d155da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers de exportaci√≥n\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def ensure_export_dir(path=\"Exportado\"):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "def next_post_id(path=\"Exportado\"):\n",
    "    \"\"\"\n",
    "    Escanea 'Exportado' y devuelve el pr√≥ximo ID tipo '001', '002', ...\n",
    "    Detecta archivos 'postXYZ.json' o 'postXYZ.md'\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(path):\n",
    "        return \"001\"\n",
    "    max_n = 0\n",
    "    for fname in os.listdir(path):\n",
    "        m = re.match(r\"post(\\d{3})\\.(json|md)$\", fname, re.IGNORECASE)\n",
    "        if m:\n",
    "            n = int(m.group(1))\n",
    "            if n > max_n:\n",
    "                max_n = n\n",
    "    return f\"{max_n+1:03d}\"\n",
    "\n",
    "def export_run(data, meta, brief, user_prompt, export_dir=\"Exportado\"):\n",
    "    \"\"\"\n",
    "    Guarda:\n",
    "      - postXYZ.json con input, prompts, output y meta\n",
    "      - postXYZ.md con texto listo para publicar\n",
    "    \"\"\"\n",
    "    ensure_export_dir(export_dir)\n",
    "    run_id = next_post_id(export_dir)\n",
    "    ts = datetime.now().isoformat(timespec=\"seconds\")\n",
    "\n",
    "    # Paquete JSON completo (para trazabilidad)\n",
    "    payload = {\n",
    "        \"timestamp\": ts,\n",
    "        \"project\": \"ESU Analytics - Marketing con IA\",\n",
    "        \"inputs\": {\n",
    "            \"brief\": brief,\n",
    "            \"system_prompt\": SYSTEM_PROMPT,\n",
    "            \"user_prompt\": user_prompt\n",
    "        },\n",
    "        \"output\": data,\n",
    "        \"meta\": meta\n",
    "    }\n",
    "\n",
    "    json_path = os.path.join(export_dir, f\"post{run_id}.json\")\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # Markdown ‚Äúlisto para publicar‚Äù\n",
    "    md_lines = []\n",
    "    md_lines.append(f\"# {data.get('titulo','(Sin t√≠tulo)')}\")\n",
    "    md_lines.append(\"\")\n",
    "    cuerpo = data.get(\"cuerpo\") or data.get(\"raw\") or \"\"\n",
    "    md_lines.append(cuerpo)\n",
    "    md_lines.append(\"\")\n",
    "    if \"cta\" in data and data[\"cta\"]:\n",
    "        md_lines.append(f\"**CTA:** {data['cta']}\")\n",
    "        md_lines.append(\"\")\n",
    "    if \"palabras\" in data:\n",
    "        md_lines.append(f\"_Palabras: {data['palabras']}_\")\n",
    "        md_lines.append(\"\")\n",
    "    md_lines.append(f\"<!-- post ID: {run_id} | {ts} | modelo: {meta.get('model')} | tokens aprox: {meta.get('total_tokens_est')} -->\")\n",
    "\n",
    "    md_path = os.path.join(export_dir, f\"post{run_id}.md\")\n",
    "    with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(md_lines))\n",
    "\n",
    "    return {\"json\": json_path, \"md\": md_path, \"id\": run_id}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8347e1a",
   "metadata": {},
   "source": [
    "## üß™ 3. Ejecuci√≥n A/B (experimentos r√°pidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08019d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "brief = {\n",
    "    \"tema\": brief_tema,\n",
    "    \"objetivo\": brief_objetivo,\n",
    "    \"audiencia\": brief_audiencia,\n",
    "    \"insight\": brief_insight,\n",
    "    \"evidencia\": brief_evidencia,\n",
    "    \"cta\": brief_cta,\n",
    "    \"restricciones\": brief_restricciones\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0a0aea",
   "metadata": {},
   "source": [
    "## üìä 4. Micro-evaluaci√≥n (manual / semiautom√°tica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cfa0307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== POST GENERADO =====\n",
      "{\n",
      "  \"titulo\": \"C√≥mo ordenar datos de ventas para decisiones m√°s informadas\",\n",
      "  \"cuerpo\": \"Sin datos limpios y consistentes, el margen de tu negocio se vuelve impredecible. Para evitar errores y mejorar tu estrategia comercial, considera estos pasos: \\n1. Unifica tus planillas de ventas. \\n2. Establece un formato est√°ndar. \\n3. Realiza auditor√≠as peri√≥dicas. \\nOrdenar tus datos no solo reduce reprocesos, sino que tambi√©n te permite tomar decisiones m√°s acertadas.\",\n",
      "  \"cta\": \"Agend√° una consulta gratuita para revisar tu caso.\",\n",
      "  \"palabras\": 102\n",
      "}\n",
      "\n",
      "===== M√âTRICAS =====\n",
      "{'elapsed_ms': 3390, 'input_tokens_est': 312, 'output_tokens_est': 138, 'total_tokens_est': 450, 'api': 'chat.completions', 'model': 'gpt-4o-mini', 'max_output_tokens': 220, 'temperature': 0.2}\n",
      "\n",
      "===== ARCHIVOS GUARDADOS =====\n",
      "{'json': 'Exportado\\\\post001.json', 'md': 'Exportado\\\\post001.md', 'id': '001'}\n"
     ]
    }
   ],
   "source": [
    "post, meta, user_prompt = generate_post(brief, temperature=0.2, max_output_tokens=220)\n",
    "paths = export_run(post, meta, brief, user_prompt, export_dir=\"Exportado\")\n",
    "\n",
    "print(\"\\n===== POST GENERADO =====\")\n",
    "print(json.dumps(post, ensure_ascii=False, indent=2))\n",
    "print(\"\\n===== M√âTRICAS =====\")\n",
    "print(meta)\n",
    "print(\"\\n===== ARCHIVOS GUARDADOS =====\")\n",
    "print(paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
