{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5337ddfe",
   "metadata": {},
   "source": [
    "# Generaci√≥n de Contenido de Marketing con IA para ESU Analytics\n",
    "\n",
    "Este notebook presenta el desarrollo final del proyecto de la materia *IA ‚Äì Generaci√≥n de Prompts*.  \n",
    "El objetivo es mostrar c√≥mo, mediante t√©cnicas de **Fast Prompting**, es posible generar de manera eficiente publicaciones de marketing digital para **ESU Analytics**, consultora orientada a PyMEs de los sectores manufacturero y comercial.  \n",
    "\n",
    "El proyecto aborda el problema de muchas PyMEs que no logran comunicar de forma clara y consistente el valor de la gesti√≥n de sus datos (ventas, precios, stock, finanzas).  \n",
    "Para resolverlo, se implementa un flujo que combina:  \n",
    "\n",
    "- **Texto ‚Üí Texto**: generaci√≥n de publicaciones en LinkedIn mediante el modelo `gpt-4o-mini`.  \n",
    "- **Texto ‚Üí Imagen**: creaci√≥n de ilustraciones conceptuales con el modelo `gpt-image-1`.  \n",
    "- **Fast Prompting** (zero-shot y one-shot), con control de tokens para optimizar costos.  \n",
    "- Exportaci√≥n autom√°tica en formatos `.json` y `.md`, asegurando trazabilidad y reproducibilidad.  \n",
    "\n",
    "Este notebook integra todo el c√≥digo y la documentaci√≥n necesaria para replicar la soluci√≥n final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9413a188",
   "metadata": {},
   "source": [
    "## Par√°metros del brief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9549cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par√°metros del brief que gu√≠an el prompt\n",
    "brief_tema = \"C√≥mo definir una estrategia comercial basada en datos\"\n",
    "brief_objetivo = \"Generar inter√©s en planificar ventas con indicadores claros\"\n",
    "brief_audiencia = \"Gerentes de ventas y due√±os de PyMEs industriales\"\n",
    "brief_insight = \"Sin objetivos medibles, los equipos de ventas operan a ciegas\"\n",
    "brief_evidencia = \"Empresas con tableros de indicadores mejoran la coordinaci√≥n y reducen reprocesos\"\n",
    "brief_cta = \"Conversemos sobre c√≥mo dise√±ar tu tablero comercial\"\n",
    "brief_restricciones = \"m√°x. 120 palabras, sin emojis ni tecnicismos excesivos\"\n",
    "\n",
    "\n",
    "# Ejemplo comentado de valores posibles:\n",
    "# brief_tema = \"C√≥mo ordenar datos de ventas para tomar decisiones mejor informadas\",\n",
    "# brief_objetivo = \"Educar y generar inter√©s por un diagn√≥stico inicial\",\n",
    "# brief_audiencia = \"Due√±os de PyMEs retail y gerentes comerciales\",\n",
    "# brief_insight = \"Sin datos limpios y consistentes, el margen se vuelve impredecible\",\n",
    "# brief_evidencia = \"Planillas dispersas generan errores; unificarlas reduce reprocesos\",\n",
    "# brief_cta = \"Agend√° una consulta gratuita para revisar tu caso\",\n",
    "# brief_restricciones = \"m√°x. 110 palabras, sin hashtags ni emojis\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100c6a78",
   "metadata": {},
   "source": [
    "## Setup (variables y helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cbec8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as y configurar cliente\n",
    "import os, time, json\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca7246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la API Key desde .env\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Tokenizer para modelos GPT-4o/mini\n",
    "ENCODING_NAME = \"o200k_base\"\n",
    "enc = tiktoken.get_encoding(ENCODING_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "676bc18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones auxiliares\n",
    "def truncate_by_tokens(text: str, max_tokens: int) -> str:\n",
    "    tokens = enc.encode(text)\n",
    "    if len(tokens) <= max_tokens:\n",
    "        return text\n",
    "    return enc.decode(tokens[:max_tokens])\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(enc.encode(text))\n",
    "\n",
    "def now_ms():\n",
    "    return round(time.time() * 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c24d6a",
   "metadata": {},
   "source": [
    "## Prompt builder (variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d33a570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"Eres un creador de contenido para ESU Analytics, consultora que ayuda a PyMEs de Manufactura y Comercio a profesionalizar su estrategia de datos (ventas, stock, estrategia comercial).\n",
    "Tu prioridad: claridad, utilidad pr√°ctica para due√±os/gerentes PyME en Argentina, tono profesional y cercano, y una llamada a la acci√≥n concreta.\n",
    "Responde siempre en espa√±ol de Buenos Aires neutral.\n",
    "\"\"\"\n",
    "\n",
    "USER_TEMPLATE = \"\"\"Tarea: Escribe un post de LinkedIn.\n",
    "\n",
    "Brief:\n",
    "- Tema: {tema}\n",
    "- Objetivo del post: {objetivo}\n",
    "- Audiencia: {audiencia}\n",
    "- √Ångulo/Insight: {insight}\n",
    "- Evidencia/ejemplo breve (opcional): {evidencia}\n",
    "- CTA: {cta}\n",
    "- Restricciones: {restricciones}\n",
    "\n",
    "Formato deseado:\n",
    "- 3‚Äì5 l√≠neas, con una idea central y un cierre con CTA.\n",
    "- Incluye 1 micro-lista de 3 √≠tems si aporta claridad.\n",
    "- No uses hashtags en esta versi√≥n.\n",
    "\n",
    "Entrega:\n",
    "Devuelve SOLO un objeto JSON con:\n",
    "{{\n",
    " \"titulo\": \"...\",\n",
    " \"cuerpo\": \"...\",\n",
    " \"cta\": \"...\",\n",
    " \"palabras\": <int>\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "def build_user_prompt(tema, objetivo, audiencia, insight, evidencia, cta, restricciones):\n",
    "    return USER_TEMPLATE.format(\n",
    "        tema=tema,\n",
    "        objetivo=objetivo,\n",
    "        audiencia=audiencia,\n",
    "        insight=insight,\n",
    "        evidencia=evidencia or \"‚Äî\",\n",
    "        cta=cta,\n",
    "        restricciones=restricciones\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b069525f",
   "metadata": {},
   "source": [
    "## Llamada a OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9204878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_post(brief, \n",
    "                  max_input_tokens=800, \n",
    "                  max_output_tokens=220, \n",
    "                  temperature=0.3):\n",
    "    user_prompt = build_user_prompt(**brief)\n",
    "    user_prompt = truncate_by_tokens(user_prompt, max_input_tokens)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\",   \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    t0 = now_ms()\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=max_output_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    dt = now_ms() - t0\n",
    "\n",
    "    text = resp.choices[0].message.content\n",
    "\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "    except Exception:\n",
    "        data = {\"raw\": text}\n",
    "\n",
    "    meta = {\n",
    "        \"elapsed_ms\": dt,\n",
    "        \"input_tokens_est\": count_tokens(SYSTEM_PROMPT) + count_tokens(user_prompt),\n",
    "        \"output_tokens_est\": count_tokens(text),\n",
    "        \"total_tokens_est\": count_tokens(SYSTEM_PROMPT) + count_tokens(user_prompt) + count_tokens(text),\n",
    "        \"api\": \"chat.completions\",\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"max_output_tokens\": max_output_tokens,\n",
    "        \"temperature\": temperature\n",
    "    }\n",
    "    # üëá devolvemos tambi√©n el prompt de usuario final para trazabilidad\n",
    "    return data, meta, user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d155da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Helpers de exportaci√≥n\n",
    "# ============================\n",
    "import os, re, json, base64\n",
    "from datetime import datetime\n",
    "\n",
    "def ensure_export_dir(path=\"Exportado\"):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "def next_post_id(path=\"Exportado\"):\n",
    "    \"\"\"\n",
    "    Escanea 'Exportado' y devuelve el pr√≥ximo ID tipo '001', '002', ...\n",
    "    Detecta archivos 'postXYZ.json' o 'postXYZ.md'\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(path):\n",
    "        return \"001\"\n",
    "    max_n = 0\n",
    "    for fname in os.listdir(path):\n",
    "        m = re.match(r\"post(\\d{3})\\.(json|md)$\", fname, re.IGNORECASE)\n",
    "        if m:\n",
    "            n = int(m.group(1))\n",
    "            if n > max_n:\n",
    "                max_n = n\n",
    "    return f\"{max_n+1:03d}\"\n",
    "\n",
    "def export_run(data, meta, brief, user_prompt, export_dir=\"Exportado\"):\n",
    "    \"\"\"\n",
    "    Guarda:\n",
    "      - postXYZ.json con input, prompts, output y meta\n",
    "      - postXYZ.md con texto listo para publicar\n",
    "    \"\"\"\n",
    "    ensure_export_dir(export_dir)\n",
    "    run_id = next_post_id(export_dir)\n",
    "    ts = datetime.now().isoformat(timespec=\"seconds\")\n",
    "\n",
    "    # Paquete JSON completo (para trazabilidad)\n",
    "    payload = {\n",
    "        \"timestamp\": ts,\n",
    "        \"project\": \"ESU Analytics - Marketing con IA\",\n",
    "        \"inputs\": {\n",
    "            \"brief\": brief,\n",
    "            \"system_prompt\": SYSTEM_PROMPT,\n",
    "            \"user_prompt\": user_prompt\n",
    "        },\n",
    "        \"output\": data,\n",
    "        \"meta\": meta\n",
    "    }\n",
    "\n",
    "    json_path = os.path.join(export_dir, f\"post{run_id}.json\")\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # Markdown ‚Äúlisto para publicar‚Äù\n",
    "    md_lines = []\n",
    "    md_lines.append(f\"# {data.get('titulo','(Sin t√≠tulo)')}\")\n",
    "    md_lines.append(\"\")\n",
    "    cuerpo = data.get(\"cuerpo\") or data.get(\"raw\") or \"\"\n",
    "    md_lines.append(cuerpo)\n",
    "    md_lines.append(\"\")\n",
    "    if \"cta\" in data and data[\"cta\"]:\n",
    "        md_lines.append(f\"**CTA:** {data['cta']}\")\n",
    "        md_lines.append(\"\")\n",
    "    if \"palabras\" in data:\n",
    "        md_lines.append(f\"_Palabras: {data['palabras']}_\")\n",
    "        md_lines.append(\"\")\n",
    "    md_lines.append(f\"<!-- post ID: {run_id} | {ts} | modelo: {meta.get('model')} | tokens aprox: {meta.get('total_tokens_est')} -->\")\n",
    "\n",
    "    md_path = os.path.join(export_dir, f\"post{run_id}.md\")\n",
    "    with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(md_lines))\n",
    "\n",
    "    return {\"json\": json_path, \"md\": md_path, \"id\": run_id}\n",
    "\n",
    "# ============================\n",
    "# Helpers para generar infograf√≠a con OpenAI Images\n",
    "# ============================\n",
    "def _extract_key_points_for_image(post, max_points=3):\n",
    "    \"\"\"\n",
    "    Extrae 2‚Äì3 ideas clave del 'cuerpo' para orientar la infograf√≠a\n",
    "    (sin texto literal; solo conceptos visuales).\n",
    "    \"\"\"\n",
    "    cuerpo = (post.get(\"cuerpo\") or post.get(\"raw\") or \"\").strip()\n",
    "    # tomar frases cortas\n",
    "    parts = [p.strip(\" -‚Ä¢*‚Äî‚Äì\\n\\r\\t \") for p in re.split(r\"[.\\n]\", cuerpo) if p.strip()]\n",
    "    parts = [p for p in parts if len(p.split()) >= 3][:max_points]\n",
    "    if not parts:\n",
    "        parts = [\"Orden de datos\", \"Decisiones informadas\", \"Control del negocio\"]\n",
    "    return parts[:max_points]\n",
    "\n",
    "def build_image_prompt_from_post(post, brief):\n",
    "    \"\"\"\n",
    "    Crea un prompt descriptivo para gpt-image-1,\n",
    "    evitando pedir texto rendereado en la imagen.\n",
    "    \"\"\"\n",
    "    titulo = post.get(\"titulo\", \"Contenido para PyMEs\")\n",
    "    puntos = _extract_key_points_for_image(post, max_points=3)\n",
    "    cta = post.get(\"cta\", \"Agend√° una consulta\")\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Ilustraci√≥n estilo renderizado profesional, colores vibrantes y corporativos (azules, naranjas, verdes). Sin texto, n√∫meros ni logotipos.\n",
    "    - Idea central: {titulo}\n",
    "    - Puntos clave: {\", \".join(puntos)}\n",
    "    Restricciones: sin personas, sin texto, sin n√∫meros, sin logotipos.\n",
    "    Sensaci√≥n buscada: profesionalismo, transformaci√≥n digital positiva.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    return prompt.strip()\n",
    "\n",
    "def generate_infographic_openai_image_from_post(\n",
    "    client, post, brief, export_dir=\"Exportado\", run_id=\"000\",\n",
    "    primary_size=\"1536x1024\", fallback_size=\"1024x1024\", low_cost=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Genera una infograf√≠a con gpt-image-1 a partir del post generado.\n",
    "\n",
    "    - Si low_cost=True ‚Üí fuerza par√°metros econ√≥micos (1024x1024, quality=\"low\", n=1).\n",
    "    - Si low_cost=False ‚Üí intenta tama√±o horizontal grande (ej. 1536x1024).\n",
    "    - Si falla (403 u otro error) ‚Üí fallback a tama√±o menor o a Pillow si est√° disponible.\n",
    "    \"\"\"\n",
    "    prompt_img = build_image_prompt_from_post(post, brief)\n",
    "\n",
    "    def _gen_and_save(size, quality=\"low\"):\n",
    "        result = client.images.generate(\n",
    "            model=\"gpt-image-1\",\n",
    "            prompt=prompt_img,\n",
    "            size=size,\n",
    "            quality=quality,\n",
    "            n=1\n",
    "        )\n",
    "        b64 = result.data[0].b64_json\n",
    "        img_bytes = base64.b64decode(b64)\n",
    "        out_path = os.path.join(export_dir, f\"post{run_id}_infografia_ai.png\")\n",
    "        with open(out_path, \"wb\") as f:\n",
    "            f.write(img_bytes)\n",
    "        return out_path\n",
    "\n",
    "    try:\n",
    "        if low_cost:\n",
    "            # ‚úÖ opci√≥n econ√≥mica (aprox. USD 0.04 por imagen en 1024x1024)\n",
    "            return _gen_and_save(\"1024x1024\", quality=\"low\")\n",
    "        else:\n",
    "            # ‚úÖ opci√≥n premium horizontal\n",
    "            return _gen_and_save(primary_size, quality=\"low\")\n",
    "    except Exception as e_primary:\n",
    "        print(f\"[Aviso] No se pudo generar en {primary_size if not low_cost else '1024x1024'}. Detalle: {e_primary}\")\n",
    "        try:\n",
    "            return _gen_and_save(fallback_size)\n",
    "        except Exception as e_fallback:\n",
    "            print(f\"[Aviso] Tampoco se pudo generar en {fallback_size}. Detalle: {e_fallback}\")\n",
    "            if PIL_OK:\n",
    "                print(\"[Fallback] Generando infograf√≠a local con Pillow‚Ä¶\")\n",
    "                ensure_export_dir(export_dir)\n",
    "                return render_infographic_pillow(post, brief, export_dir=export_dir, run_id=run_id)\n",
    "            else:\n",
    "                raise RuntimeError(\n",
    "                    \"No se pudo generar imagen con gpt-image-1 (acceso denegado) \"\n",
    "                    \"y Pillow no est√° instalado. Verific√° tu organizaci√≥n en OpenAI \"\n",
    "                    \"o instal√° Pillow con: pip install pillow\"\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8347e1a",
   "metadata": {},
   "source": [
    "## Ejecuci√≥n A/B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08019d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "brief = {\n",
    "    \"tema\": brief_tema,\n",
    "    \"objetivo\": brief_objetivo,\n",
    "    \"audiencia\": brief_audiencia,\n",
    "    \"insight\": brief_insight,\n",
    "    \"evidencia\": brief_evidencia,\n",
    "    \"cta\": brief_cta,\n",
    "    \"restricciones\": brief_restricciones\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0a0aea",
   "metadata": {},
   "source": [
    "## Micro-evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cfa0307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== POST GENERADO =====\n",
      "{\n",
      "  \"titulo\": \"Definiendo una Estrategia Comercial Basada en Datos\",\n",
      "  \"cuerpo\": \"Sin objetivos medibles, los equipos de ventas operan a ciegas. Para optimizar tu estrategia comercial, considera estos tres puntos clave: 1) Establece indicadores claros, 2) Monitorea el rendimiento en tiempo real, 3) Ajusta tus t√°cticas seg√∫n los datos. Empresas que implementan tableros de indicadores mejoran la coordinaci√≥n y reducen reprocesos. No dejes que tu equipo navegue sin rumbo.\",\n",
      "  \"cta\": \"Conversemos sobre c√≥mo dise√±ar tu tablero comercial.\",\n",
      "  \"palabras\": 102\n",
      "}\n",
      "\n",
      "===== M√âTRICAS =====\n",
      "{'elapsed_ms': 3479, 'input_tokens_est': 306, 'output_tokens_est': 143, 'total_tokens_est': 449, 'api': 'chat.completions', 'model': 'gpt-4o-mini', 'max_output_tokens': 220, 'temperature': 0.2}\n",
      "\n",
      "===== ARCHIVOS GUARDADOS =====\n",
      "{'json': 'Exportado\\\\post042.json', 'md': 'Exportado\\\\post042.md', 'id': '042'}\n"
     ]
    }
   ],
   "source": [
    "post, meta, user_prompt = generate_post(brief, temperature=0.2, max_output_tokens=220)\n",
    "paths = export_run(post, meta, brief, user_prompt, export_dir=\"Exportado\")\n",
    "\n",
    "print(\"\\n===== POST GENERADO =====\")\n",
    "print(json.dumps(post, ensure_ascii=False, indent=2))\n",
    "print(\"\\n===== M√âTRICAS =====\")\n",
    "print(meta)\n",
    "print(\"\\n===== ARCHIVOS GUARDADOS =====\")\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fcacb7",
   "metadata": {},
   "source": [
    "## Generaci√≥n de imagen (OpenAI Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c27cb1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Imagen =====\n",
      "Imagen guardada en: Exportado\\post042_infografia_ai.png\n"
     ]
    }
   ],
   "source": [
    "# Usamos el mismo ID que se gener√≥ al exportar el post para mantener trazabilidad\n",
    "export_dir = \"Exportado\"\n",
    "run_id = paths[\"id\"]\n",
    "\n",
    "# Generar infograf√≠a con OpenAI Images\n",
    "img_path = generate_infographic_openai_image_from_post(\n",
    "    client=client,\n",
    "    post=post,\n",
    "    brief=brief,\n",
    "    export_dir=export_dir,\n",
    "    run_id=run_id,\n",
    "    low_cost=True  # Cambiar a False para intentar 1536x1024 (m√°s caro)\n",
    ")\n",
    "\n",
    "print(\"\\n===== Imagen =====\")\n",
    "print(\"Imagen guardada en:\", img_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed954b5",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "\n",
    "El proyecto logr√≥ cumplir con los objetivos propuestos:  \n",
    "- Se resolvi√≥ la problem√°tica de generar contenido claro y atractivo para PyMEs, utilizando exclusivamente modelos de IA generativa.  \n",
    "- Se aplicaron t√©cnicas de **Fast Prompting** para obtener resultados consistentes y reducir costos mediante control de tokens.  \n",
    "- Se integraron de manera efectiva dos modalidades: **texto‚Äìtexto** y **texto‚Äìimagen**, cumpliendo con los requisitos del curso.  \n",
    "- Se garantiz√≥ la **trazabilidad** de cada ejecuci√≥n, almacenando inputs, outputs y m√©tricas de uso.  \n",
    "\n",
    "Los resultados muestran que la metodolog√≠a es **viable, escalable y orientada a resultados**, aportando valor tanto en el plano acad√©mico (demostraci√≥n de conceptos aprendidos) como en el profesional (aplicaci√≥n real en la estrategia digital de ESU Analytics).  \n",
    "\n",
    "**Pr√≥ximos pasos sugeridos:** ampliar la variedad de briefs, experimentar con estilos gr√°ficos alternativos y medir m√©tricas reales de impacto en redes sociales (engagement, alcance).  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
